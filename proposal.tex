%% bare_conf.tex
%% V1.3
%% 2007/01/11
%% by Michael Shell
%% See:
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.7 or later) with an IEEE conference paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/tex-archive/macros/latex/contrib/IEEEtran/
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%
%% File list of work: IEEEtran.cls, IEEEtran_HOWTO.pdf, bare_adv.tex,
%%                    bare_conf.tex, bare_jrnl.tex, bare_jrnl_compsoc.tex
%%*************************************************************************

\documentclass[conference]{IEEEtran}

\ifCLASSINFOpdf
\else
\fi

\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}

\title{A Survey of Techniques for Automated Code Evaluation and Review}

\author{\IEEEauthorblockN{Beatrice \AA kerblom}
\IEEEauthorblockA{Department of Computer and Systems Sciences \\
Stockholm University\\
Stockholm, Sweden\\
Email: {\tt beatrice@dsv.su.se}}
\and
\IEEEauthorblockN{Peter Idestam-Almquist\\ 
}
\IEEEauthorblockA{Department of Computer and Systems Sciences \\
Stockholm University\\
Stockholm, Sweden\\
Email: {\tt pi@dsv.su.se}}}

\maketitle


\begin{abstract}
In this paper we present a small survey made to find out what has
been done in the area of automatic programming assignment
assessement and review. Many attempts have been made to produce a
solution for the problem, but the results are mainly at a
prototype level or below. The systems are all built for
researching the area, rather than for use on real courses. 

\end{abstract}

\IEEEpeerreviewmaketitle



\section{Introduction and Background}
A current trend in university education is to increase the amount
of resources that are available for the students online. This way,
the students can, to a greater extent, plan their work
individually which may be a prerequisite for non-traditional
students. 

The flipped classroom idea is in short a way of making better use
of the time that students and teachers spend at the same
location. Students prepare for classroom sessions (lectures) by
e.g. watching short snippets of pre-recorded lectures. These
videos are often followed up by a quiz or questionnaire for the
student where the understanding gained from the video lecture is
assessed. The results from the questionnaire can then be used by
the teacher for tailoring the classroom sessions e.g. emphasizing
parts that many students misunderstood or did not remember.

To be useful, the interpretation of the data from the quizzes or
questionnaires must be automatic. If the questionnaire questions
are all multiple choice, the interpretation will be easily
done. On programming courses, though, there is also a need to
understand if students can write code, e.g. fill in short snippets
in existing code to illustrate an algorithm. To make it possible
to use programming in these follow-up quizzes, the assessment of
the students' answers must be made automatic.



\section{Paper Summaries}

\subsection{Assessment Process for Programming Assignments}

Ala-Mutka and J\"{a}rvinen
\cite{Ala-Mutka:2004:APP:1018423.1019977} describe the work
process of assessing programming assignments and present a partly
automatic assessment tool. Students do not practice programming on
their own initiative. This means that practical programming
assignments must be made mandatory and that they must be assessed
during courses. 

Correct functionality, good design, and good programming style are
often required when assessing programming assignments, but their
definition and relative importance vary between courses and
different teachers. Automatic assessment would mean that the
assessment marking would be the same for all students. 

The tool assesses that the program passes the compiler, its
dynamic behavior in terms of output, memory management and
efficiency, and also compatibility with required coding
guidelines. After passing the automatised assessment, the
teachers will comtinue with manual assessment.  


\subsection{Automated Assessment of Programming Assignments}

Pieterse \cite{Pieterse:2013:AAP:2541917.2541921} reports on the
development of a new assessment tool based on the success factors
and concerns collected from previous work by other researchers.

\paragraph{Sucess factors} High quality assignments, clear
formulation of tasks, well chosen test-data, good feedback,
unlimited submissions, students must beunderstand how testing
 (TDD) works, and additional support must be available. 

\paragraph{Issues} Assignment design requires great efforts,
workload may increase instead of decrease, very strict
requirements suppresses creativity, increase in plagiarism, skills
are needed to use the system itself, malicious programs
(deliberate or not), limits in what can be assessed.  

The use of automatic assessment tools makes it possible to give
the students more exercises and feedback in a flexible way when
suitable for the students and should be used in all MOOCs (massive
open online courses). The assessment system presented in the
article is based on the running of tests and the evaluation of the
use resulted in a list of recommendations to anyone planning to
implement their own automatic assessment tool. 

\paragraph{Recommendations} The system must provide a secure
environment for execution, the system must support the instructors
in designing test cases, ith should be possible to provide
scaffolding and parts of programs, resubmission should be allowed,
it must allow variations in output formatting, it should allow the
instructor to provide qualitative feedback, it should be able to
report on quality metrics, statistical information about students'
performance should be collected and optionally shown to them. 

\subsection{Programming Assignments Automatic Grading: Review of Tools and Implementations}

The paper \cite{CaizaDelAlamo13} describes 11 tools for automated grading of programming assignments. These tools have primarily been developed at different universities, and none of these tools seems to be widely used. The older tools, which are more mature, were usually standalone programs, while the newer tools are usually plugins to LMS systems and most often to Moodle.

The authors identify that the lack of a grading model for assignments is an important gap in the reviewed tools. Therefore, as a first step towards a grading model, they provide a characterization of evaluation metrics. Most tools support dynamic analysis, which is assessment by executing the program, by testing correctness using test cases. Some tools support static analysis but the paper does not analyze in detail the different metrics and quality of the static analysis. The tool which seem to support the most sophisticated static analysis is CourseMarker developed by Nottingham University \cite{HigginsEtAl05}.

The static analysis is of course the most interesting part since the dynamic analysis provided by the tools is mainly the same support for running tests as you get with standard build servers. 

\subsection{Review of Recent Systems for Automatic Assessment of Programming Assignments}

In \cite{Ihantola:2010:RRS:1930464.1930480} the authors raise
the question why there exists so many automatic assessment systems
with the same functionality. The reason seems to be that most
systems are developed by researchers and teachers for their own
use, and very few systems actually emerge as supported pieces of
software. The main part of the paper focuses on features rather
than systems.

Resubmission of assignments could encourage students to a mindless trial and error problem solving method, and many tools have submission limitations to hinder such behaviour. The authors mention that is often a good idea to combine automatic and manual assessment. They also point out that, when running submitted student solutions, it is important to secure the server against malicious or incorrect code.

It is disappointing that many systems mentioned in the litterature
are just prototypes and not publically 
available.

Concurrent programming assignments are especially hard to test for correctness.

Letting students write tests for themselves or reviewing code of other students is often a good idea from a pedagogical perspective.

The authors conclude that is important that the developers of automatic assessment systems describe in more detail how the system actually work. They argue that by publishing the code of the systems as open source would help getting the systems to be more willingly adopted by others. 

\section{Further Ideas?}

Depending on the context in which the assessment tool is supposed
to be used, the requirements for how it can be used will be
different. In MOOCs (massive open online courses), the use of an
assessment tool will be entirely formative to its nature. If used
in blended learning campus courses, the use of formative
assessment tools may still be great, but it would also be
beneficial if it could support teachers in their summative
assessments. 

Standalone systems vs. Moodle plugins.

What kind of metrics would we like to produce for the programs?
E.g. coupling/cohesion. 

How many students are needed for motivating the use of an
automated assessment system? At what point does it become
``cheaper'' per student?

\section{Conclusion}

The field of automated programming assignment assessment seems
surprisingly immature. As far as we have seen, there seem to exist
no fully developed off-the-shelf tool which is widely used. 

The systems we have encountered are all prototypes developed for
research purposes, that is researching automated assessment,
rather than tools used in large contexts.

Nevertheless, the interest for using automated assessment seems to
be big and increasing, especially in the light of MOOCs and recent
pedagogical ideas as the flipped classroom. 

\begin{thebibliography}{1}

\bibitem{Ala-Mutka:2004:APP:1018423.1019977}
  Ala-Mutka, Kirsti and Jarvinen, Hannu-Matti,
  {\it Assessment Process for Programming Assignments},
  In Proceedings of ICALT '04,  pages 181--185, 2004.

\bibitem{Ihantola:2010:RRS:1930464.1930480}
  Ihantola, Petri and Ahoniemi, Tuukka and Karavirta, Ville and Sepp\"{a}l\"{a}, Otto,
 {\it Review of Recent Systems for Automatic Assessment of Programming Assignments},
 In proceedings of Koli Calling '10, pages 86--93, 
 Koli, Finland, 2010.

\bibitem{Pieterse:2013:AAP:2541917.2541921}
  Vreda Pieterse, 
  {\it Automated Assessment of Programming Assignments},
  In Proceedings of CSERC '13, pages 4:45--4:56, 2013.

\bibitem{CaizaDelAlamo13}
Julio C. Caiza, Jose M. Del Alamo
{\it Programming Assignments Automatic Grading: Review of Tools and Implementations}
Universidad Politécnica de Madrid (SPAIN)
2013.

\bibitem{HigginsEtAl05}
Higgins, C. A., Gray, G., Symeonidis, P., Tsintsifas, A.  
{\it Automated Assessment and Experiences of Teaching Programming.} 
Journal on Educational Resources in Computing (JERIC), vol. 5, pp. 5.
2005.

 
\end{thebibliography}




% that's all folks
\end{document}


codess
